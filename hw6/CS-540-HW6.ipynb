{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('Pytorch')",
   "metadata": {
    "interpreter": {
     "hash": "d2a50202da547d5f1664113eb8638e738c56988fb99fe0d3bdc955928e514fae"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " Train Epoch: 0 Accuracy: 4513/60000(7.52%) Loss: 2.304\n",
      "\n",
      " Train Epoch: 1 Accuracy: 9026/60000(15.04%) Loss: 1.152\n",
      "\n",
      " Train Epoch: 2 Accuracy: 13539/60000(22.56%) Loss: 0.768\n",
      "\n",
      " Train Epoch: 3 Accuracy: 18052/60000(30.09%) Loss: 0.576\n",
      "\n",
      " Train Epoch: 4 Accuracy: 22565/60000(37.61%) Loss: 0.461\n",
      "0.0715\n",
      "0.0715\n"
     ]
    }
   ],
   "source": [
    "# Many imports, so many imports:\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_data_loader(training = True):\n",
    "\n",
    "    # Define our custom transformation:\n",
    "    custom_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    \n",
    "    # Get the training and test datasets:\n",
    "    train_set = datasets.MNIST('./data', train = True, transform = custom_transform, download = True)\n",
    "    test_set = datasets.MNIST('./data', train = False, transform = custom_transform)\n",
    "\n",
    "    # If statement to catch training value:\n",
    "    if (training == False):\n",
    "        # If true, return test_set:\n",
    "        loader = torch.utils.data.DataLoader(test_set, batch_size = 50, shuffle = False)\n",
    "    \n",
    "    else:\n",
    "        # Otherwise, return training_set:\n",
    "        loader = torch.utils.data.DataLoader(train_set, batch_size = 50)\n",
    "    \n",
    "    return loader\n",
    "\n",
    "train_loader = get_data_loader()\n",
    "\n",
    "test_loader = get_data_loader(False)\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "\n",
    "        # Flatten layer, this converts the 2D array to 1D:\n",
    "        nn.Flatten(),\n",
    "\n",
    "        # Add a dense layer of 128 nodes, then ReLU Activation:\n",
    "        nn.Linear(784, 128),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        # Add a dense layer of 64 nodes, then ReLU Activation:\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        # Add a dense layer of 10 nodes:\n",
    "        nn.Linear(64, 10),\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "###################### Do not edit above this line: ######################\n",
    "def train_model(model, train_loader, criterion, T):\n",
    "\n",
    "    # Set the model to training mode:\n",
    "    model.train()\n",
    "\n",
    "    # Optimization function:\n",
    "    opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    index = 0\n",
    "    accurate = 0\n",
    "\n",
    "    # Iterate through the dataset:\n",
    "    for epoch in range(0, T):\n",
    "        totalLoss = 0.0\n",
    "        trainset = get_data_loader(True)\n",
    "\n",
    "        for i, data in enumerate(trainset, 0):\n",
    "            index += 1\n",
    "            inputs, labels = data\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Backwards + step:\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step\n",
    "\n",
    "            totalLoss += loss.item()\n",
    "\n",
    "            _, predict = torch.max(outputs.data, 1)\n",
    "            #totalLoss += labels.size(0)\n",
    "            accurate += (predict == labels).sum().item()\n",
    "\n",
    "            \n",
    "        #Printing\n",
    "        length =  len(trainset.dataset)\n",
    "        printThings = [epoch, accurate, length, round((accurate/length)*100, 2), round(totalLoss/index, 3)]\n",
    "        print('\\n Train Epoch: {} Accuracy: {}/{}({}%) Loss: {}'.format(*printThings))\n",
    "        totalLoss = 0.0\n",
    "\n",
    "train_model(model, train_loader, criterion, T = 5)\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, show_loss = True):\n",
    "\n",
    "    index = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(correct/total)\n",
    "\n",
    "evaluate_model(model, test_loader, criterion, show_loss = False)\n",
    "evaluate_model(model, test_loader, criterion, show_loss = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My code\n",
    "\"\"\"\n",
    "def train_model(model, train_loader, criterion, T):\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Loop over the dataset multiple times:\n",
    "    for epoch in range(T):\n",
    "        total_loss = 0.0\n",
    "        trainset = get_data_loader(True)\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # Get the inputs:\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # Zero the gradients:\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # Forward / Backward and optimize:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # Print the stats:\n",
    "            total_loss += loss.item()\n",
    "            printThings = [epoch, index, enumerate(trainset), index/len(trainset), loss.item()]\n",
    "            print('\\n Train Epoch: {} Accuracy: {}/{}({}%) Loss: {}'.format(*printThings))\n",
    "\n",
    "train_model(model, train_loader, criterion, T = 5)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, show_loss = True):\n",
    "\n",
    "    # Change the model to evaluation mode:\n",
    "    model.eval()\n",
    "\n",
    "    # Do not track gradients, then loop through the test_loader:\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            # If true print the loss stat:\n",
    "            if (show_loss == True):\n",
    "                print(\"Average Loss: \", )\n",
    "\n",
    "            # Always print the accuracy:\n",
    "            print(\"Accuracy: \", )\n",
    "\n",
    "def predict_label(model, test_images, index):\n",
    "    \n",
    "    # Need to use the softmax tool:\n",
    "    prob = F.softmax(logits, dim = )\n",
    "\n",
    "    # Create class names for classification:\n",
    "    class_names = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, show_loss = True):\n",
    "\n",
    "    index = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(correct/total)\n",
    "\n",
    "evaluate_model(model, test_loader, criterion, show_loss = False)\n",
    "evaluate_model(model, test_loader, criterion, show_loss = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "printThings = [epoch, accurate, length, round((accurate/length)*100, 2), round(totalLoss, 3)/index]\n",
    "        print('\\n Train Epoch: {} Accuracy: {}/{}({}%) Loss: {}'.format(*printThings))\n",
    "\n",
    "\n",
    "for val in (predict == labels):\n",
    "                if val == True:\n",
    "                    accurate += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    accurate = 0\n",
    "    for epoch in range(0, T):\n",
    "        totalLoss = 0.0\n",
    "        trainset = get_data_loader(True)\n",
    "        for i, data in enumerate(trainset, 0):\n",
    "            index += 1\n",
    "            inputs, labels = data\n",
    "            opt.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step\n",
    "            totalLoss += loss.item()\n",
    "\n",
    "            #, predict = torch.max(outputs, 1)\n",
    "            #\n",
    "            #for val in (predict == labels):\n",
    "            #    if val == True:\n",
    "            #        accurate += 1\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in trainset:\n",
    "                    images, labels = data\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "        #Printing\n",
    "        length =  len(trainset.dataset)\n",
    "        printThings = [epoch, correct, length, round((correct/length)*100, 2), round(totalLoss/index, 3)]\n",
    "        print('\\n Train Epoch: {} Accuracy: {}/{}({}%) Loss: {}'.format(*printThings))\n",
    "        index = 0\n",
    "        totalLoss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Code ~ 83%\n",
    "\n",
    "# Set the model to training mode:\n",
    "    model.train()\n",
    "\n",
    "    # Optimization function:\n",
    "    opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    index = 0\n",
    "    accurate = 0\n",
    "\n",
    "    # Iterate through the dataset:\n",
    "    for epoch in range(0, T):\n",
    "        totalLoss = 0.0\n",
    "        trainset = get_data_loader(True)\n",
    "\n",
    "        for i, data in enumerate(trainset, 0):\n",
    "            index += 1\n",
    "            inputs, labels = data\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Backwards + step:\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step\n",
    "\n",
    "            totalLoss += loss.item()\n",
    "\n",
    "            _, predict = torch.max(outputs.data, 1)\n",
    "            #totalLoss += labels.size(0)\n",
    "            accurate += (predict == labels).sum().item()\n",
    "\n",
    "            \n",
    "        #Printing\n",
    "        length =  len(trainset.dataset)\n",
    "        printThings = [epoch, accurate, length, round((accurate/length)*100, 2), round(totalLoss, 3)/index]\n",
    "        print('\\n Train Epoch: {} Accuracy: {}/{}({}%) Loss: {}'.format(*printThings))\n",
    "        totalLoss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    correct = 0\n",
    "    total = 0.0\n",
    "    totalLoss = 0.0\n",
    "    for epoch in range(0, T):\n",
    "        trainset = get_data_loader(True)\n",
    "        total = 0.0\n",
    "        totalLoss = 0.0\n",
    "        correct = 0.0\n",
    "        for i, data in enumerate(trainset, 0):\n",
    "            inputs, labels = data\n",
    "            opt.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step\n",
    "            totalLoss += loss.item()\n",
    "\n",
    "            total += labels.size(0)\n",
    "            with torch.no_grad():\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % len(trainset) == len(trainset) - 1:\n",
    "                length =  len(trainset.dataset)\n",
    "                printThings = [epoch, correct, length, round((correct/length)*100, 2), round(totalLoss/total, 3)]\n",
    "                print('\\n Train Epoch: {} Accuracy: {}/{}({}%) Loss: {}'.format(*printThings))"
   ]
  }
 ]
}